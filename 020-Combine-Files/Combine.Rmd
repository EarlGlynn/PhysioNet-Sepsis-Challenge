---
title: "Combine PhysioNet Challenge 2019 Files"
output:
  html_document:
    toc: yes
    number_sections: yes
  html_notebook:
    toc: yes
---

<style type="text/css">
div#TOC li {
    list-style:none;
    background-image:none;
    background-repeat:none;
    background-position:0;
}
</style> 

efg | 2019-02-24

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
time.1 <- Sys.time()  
```

Combine all 5000 2019 challenge files into a single file for analysis.

# Setup

Directory structure

```
PhysioNet-2019
    raw
    data
        training
    R
        000-Download
        010-Count-Characters
        020-Combine-Files
        ...
```

## Packages

```{r, comment=NA}
library(tidyverse)
library(kableExtra) # kable_styling
library(writexl)
```

## Helper function

```{r}
Show <- function(data, caption="", bigMark="")
{
  data                                          %>%
  kable("html",
        caption=caption,
        format.args = list(big.mark=bigMark))   %>%
  kable_styling(bootstrap_options = c("striped", "bordered", "condensed"),
                position = "left", full_width = FALSE)
}
```                  

# Make list of PhysioNet .psv files

Assume 5000 files previously unzipped into this directory relative to project directory.

```{r, comment=NA}
dataDIR <- "../../data/training" 
files <- list.files(dataDIR, full.names=TRUE)
length(files)
```

# Combine all files into single tibble

## Function to read single .psv file

Add filename as first column.  Move ICULOS to second column.

```{r}
readPSV <- function(filepath)
{
  filename <- substr(basename(filepath), 1, nchar(basename(filepath))-4)
  d <-  
    read_delim(filepath, "|", col_types = cols(.default = col_double()))  %>%
    mutate(patient = filename)                                            %>%
    select(patient, ICULOS, everything())
  
  d
}
```

## map_df from purrr does heavy lifting

[Reading and combining many tidy data files in R](https://serialmentor.com/blog/2016/6/13/reading-and-combining-many-tidy-data-files-in-R).

```{r, comment=NA}
allData <- files %>%
  map_df(readPSV)  

nrow(allData)
```

## Is the record count correct?

The file **character-counts.xlsx** from the **010-Count-Characters** quality check, shows a total of 193,453 line feeds in the 5000 files.  If we take out the 5000 header records, this leaves 188,453 data records, which matches the count above. 

## Structure of tibble

```{r, comment=NA}
str(allData)
```

## Write to Excel file

```{r}
write_xlsx(allData, "../../data/PhysioNet-2019-Raw-Data.xlsx")
```

## Save R object for quicker loading later

```{r}
save(allData, file = "../../data/PhysioNet-2019-Raw-Data.RData")
```

# Record counts

## All data

```{r}
allDataCounts <- 
  allData                                     %>%
  summarize(nRecord  = n(),
            nPatient = n_distinct(patient))

allDataCounts %>%
  Show()
```

## Sepsis records

```{r}
sepsisDataCounts <-
  allData                   %>%
  filter(SepsisLabel == 1)  %>%
  summarize(nRecord  = n(),
            nPatient = n_distinct(patient)) 

sepsisDataCounts %>%
  Show()
```

## % Sepsis

```{r, comment=NA}
sepsisDataCounts$nRecord
allDataCounts$nRecord

sprintf("%.2f%% sepsis records",
        100 * sepsisDataCounts$nRecord  / allDataCounts$nRecord)
```

```{r, comment=NA}
sepsisDataCounts$nPatient
allDataCounts$nPatient

sprintf("%.2f%% sepsis patients",
        100 * sepsisDataCounts$nPatient / allDataCounts$nPatient)
```

# Sample records

```{r}
head(allData)  %>% Show()
```

```{r}
tail(allData) %>% Show()
```

```{r, echo=FALSE}
time.2 <- Sys.time()
processingTime <- paste("Processing time:", sprintf("%.1f",
                        as.numeric(difftime(time.2,
                                            time.1, units="secs"))), "secs\n")
```

`r processingTime`
`r format(time.2, "%Y-%m-%d %H%M")`                      